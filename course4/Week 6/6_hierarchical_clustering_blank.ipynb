{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hierarchical clustering** refers to a class of clustering methods that seek to build a **hierarchy** of clusters, in which some clusters contain others. In this assignment, we will explore a top-down approach, recursively bipartitioning the data using k-means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note to Amazon EC2 users**: To conserve memory, make sure to stop all the other notebooks before running this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block will check if you have the correct version of GraphLab Create. Any version later than 1.8.5 will do. To upgrade, read [this page](https://turi.com/download/upgrade-graphlab-create.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Check GraphLab Create version'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import graphlab\n",
    "import turicreate as graphlab\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances\n",
    "%matplotlib inline\n",
    "\n",
    "'''Check GraphLab Create version'''\n",
    "# from distutils.version import StrictVersion\n",
    "# assert (StrictVersion(graphlab.version) >= StrictVersion('1.8.5')), 'GraphLab Create must be version 1.8.5 or later.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Wikipedia dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki = graphlab.SFrame('people_wiki.gl/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we did in previous assignments, let's extract the TF-IDF features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki['tf_idf'] = graphlab.text_analytics.tf_idf(wiki['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">URI</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">name</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">&lt;http://dbpedia.org/resou<br>rce/Digby_Morrell&gt; ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Digby Morrell</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">digby morrell born 10<br>october 1979 is a former ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">&lt;http://dbpedia.org/resou<br>rce/Alfred_J._Lewy&gt; ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Alfred J. Lewy</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">alfred j lewy aka sandy<br>lewy graduated from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">&lt;http://dbpedia.org/resou<br>rce/Harpdog_Brown&gt; ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Harpdog Brown</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">harpdog brown is a singer<br>and harmonica player who ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">&lt;http://dbpedia.org/resou<br>rce/Franz_Rottensteiner&gt; ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Franz Rottensteiner</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">franz rottensteiner born<br>in waidmannsfeld lower ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">&lt;http://dbpedia.org/resou<br>rce/G-Enka&gt; ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">G-Enka</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">henry krvits born 30<br>december 1974 in tallinn ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">&lt;http://dbpedia.org/resou<br>rce/Sam_Henderson&gt; ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Sam Henderson</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">sam henderson born<br>october 18 1969 is an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">&lt;http://dbpedia.org/resou<br>rce/Aaron_LaCrate&gt; ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Aaron LaCrate</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">aaron lacrate is an<br>american music producer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">&lt;http://dbpedia.org/resou<br>rce/Trevor_Ferguson&gt; ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Trevor Ferguson</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">trevor ferguson aka john<br>farrow born 11 november ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">&lt;http://dbpedia.org/resou<br>rce/Grant_Nelson&gt; ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Grant Nelson</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">grant nelson born 27<br>april 1971 in london  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">&lt;http://dbpedia.org/resou<br>rce/Cathy_Caruth&gt; ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Cathy Caruth</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">cathy caruth born 1955 is<br>frank h t rhodes ...</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[10 rows x 3 columns]<br/>\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\tURI\tstr\n",
       "\tname\tstr\n",
       "\ttext\tstr\n",
       "\n",
       "Rows: 10\n",
       "\n",
       "Data:\n",
       "+-------------------------------+---------------------+\n",
       "|              URI              |         name        |\n",
       "+-------------------------------+---------------------+\n",
       "| <http://dbpedia.org/resour... |    Digby Morrell    |\n",
       "| <http://dbpedia.org/resour... |    Alfred J. Lewy   |\n",
       "| <http://dbpedia.org/resour... |    Harpdog Brown    |\n",
       "| <http://dbpedia.org/resour... | Franz Rottensteiner |\n",
       "| <http://dbpedia.org/resour... |        G-Enka       |\n",
       "| <http://dbpedia.org/resour... |    Sam Henderson    |\n",
       "| <http://dbpedia.org/resour... |    Aaron LaCrate    |\n",
       "| <http://dbpedia.org/resour... |   Trevor Ferguson   |\n",
       "| <http://dbpedia.org/resour... |     Grant Nelson    |\n",
       "| <http://dbpedia.org/resour... |     Cathy Caruth    |\n",
       "+-------------------------------+---------------------+\n",
       "+-------------------------------+\n",
       "|              text             |\n",
       "+-------------------------------+\n",
       "| digby morrell born 10 octo... |\n",
       "| alfred j lewy aka sandy le... |\n",
       "| harpdog brown is a singer ... |\n",
       "| franz rottensteiner born i... |\n",
       "| henry krvits born 30 decem... |\n",
       "| sam henderson born october... |\n",
       "| aaron lacrate is an americ... |\n",
       "| trevor ferguson aka john f... |\n",
       "| grant nelson born 27 april... |\n",
       "| cathy caruth born 1955 is ... |\n",
       "+-------------------------------+\n",
       "[10 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run k-means on this dataset, we should convert the data matrix into a sparse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from em_utilities import sframe_to_scipy # converter\n",
    "\n",
    "# # This will take about a minute or two.\n",
    "# tf_idf, map_index_to_word = sframe_to_scipy(wiki, 'tf_idf')\n",
    "\n",
    "def load_sparse_csr(filename):\n",
    "    loader = np.load(filename)\n",
    "    data = loader['data']\n",
    "    indices = loader['indices']\n",
    "    indptr = loader['indptr']\n",
    "    shape = loader['shape']\n",
    "    \n",
    "    return csr_matrix( (data, indices, indptr), shape)\n",
    "\n",
    "tf_idf = load_sparse_csr('people_wiki_tf_idf.npz')\n",
    "map_index_to_word = graphlab.SFrame('people_wiki_map_index_to_word.gl/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be consistent with the k-means assignment, let's normalize all vectors to have unit norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "tf_idf = normalize(tf_idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bipartition the Wikipedia dataset using k-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall our workflow for clustering text data with k-means:\n",
    "\n",
    "1. Load the dataframe containing a dataset, such as the Wikipedia text dataset.\n",
    "2. Extract the data matrix from the dataframe.\n",
    "3. Run k-means on the data matrix with some value of k.\n",
    "4. Visualize the clustering results using the centroids, cluster assignments, and the original dataframe. We keep the original dataframe around because the data matrix does not keep auxiliary information (in the case of the text dataset, the title of each article).\n",
    "\n",
    "Let us modify the workflow to perform bipartitioning:\n",
    "\n",
    "1. Load the dataframe containing a dataset, such as the Wikipedia text dataset.\n",
    "2. Extract the data matrix from the dataframe.\n",
    "3. Run k-means on the data matrix with k=2.\n",
    "4. Divide the data matrix into two parts using the cluster assignments.\n",
    "5. Divide the dataframe into two parts, again using the cluster assignments. This step is necessary to allow for visualization.\n",
    "6. Visualize the bipartition of data.\n",
    "\n",
    "We'd like to be able to repeat Steps 3-6 multiple times to produce a **hierarchy** of clusters such as the following:\n",
    "```\n",
    "                      (root)\n",
    "                         |\n",
    "            +------------+-------------+\n",
    "            |                          |\n",
    "         Cluster                    Cluster\n",
    "     +------+-----+             +------+-----+\n",
    "     |            |             |            |\n",
    "   Cluster     Cluster       Cluster      Cluster\n",
    "```\n",
    "Each **parent cluster** is bipartitioned to produce two **child clusters**. At the very top is the **root cluster**, which consists of the entire dataset.\n",
    "\n",
    "Now we write a wrapper function to bipartition a given cluster using k-means. There are three variables that together comprise the cluster:\n",
    "\n",
    "* `dataframe`: a subset of the original dataframe that correspond to member rows of the cluster\n",
    "* `matrix`: same set of rows, stored in sparse matrix format\n",
    "* `centroid`: the centroid of the cluster (not applicable for the root cluster)\n",
    "\n",
    "Rather than passing around the three variables separately, we package them into a Python dictionary. The wrapper function takes a single dictionary (representing a parent cluster) and returns two dictionaries (representing the child clusters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bipartition(cluster, maxiter=400, num_runs=4, seed=None):\n",
    "    '''cluster: should be a dictionary containing the following keys\n",
    "                * dataframe: original dataframe\n",
    "                * matrix:    same data, in matrix format\n",
    "                * centroid:  centroid for this particular cluster'''\n",
    "    \n",
    "    data_matrix = cluster['matrix']\n",
    "    dataframe   = cluster['dataframe']\n",
    "    \n",
    "    # Run k-means on the data matrix with k=2. We use scikit-learn here to simplify workflow.\n",
    "    kmeans_model = KMeans(n_clusters=2, max_iter=maxiter, n_init=num_runs, random_state=seed, n_jobs=1, verbose=1)\n",
    "    kmeans_model.fit(data_matrix)\n",
    "    centroids, cluster_assignment = kmeans_model.cluster_centers_, kmeans_model.labels_\n",
    "    \n",
    "    # Divide the data matrix into two parts using the cluster assignments.\n",
    "    data_matrix_left_child, data_matrix_right_child = data_matrix[cluster_assignment==0], \\\n",
    "                                                      data_matrix[cluster_assignment==1]\n",
    "    \n",
    "    # Divide the dataframe into two parts, again using the cluster assignments.\n",
    "    cluster_assignment_sa = graphlab.SArray(cluster_assignment) # minor format conversion\n",
    "    dataframe_left_child, dataframe_right_child     = dataframe[cluster_assignment_sa==0], \\\n",
    "                                                      dataframe[cluster_assignment_sa==1]\n",
    "        \n",
    "    \n",
    "    # Package relevant variables for the child clusters\n",
    "    cluster_left_child  = {'matrix': data_matrix_left_child,\n",
    "                           'dataframe': dataframe_left_child,\n",
    "                           'centroid': centroids[0]}\n",
    "    cluster_right_child = {'matrix': data_matrix_right_child,\n",
    "                           'dataframe': dataframe_right_child,\n",
    "                           'centroid': centroids[1]}\n",
    "    \n",
    "    return (cluster_left_child, cluster_right_child)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell performs bipartitioning of the Wikipedia dataset. Allow 20-60 seconds to finish.\n",
    "\n",
    "Note. For the purpose of the assignment, we set an explicit seed (`seed=1`) to produce identical outputs for every run. In pratical applications, you might want to use different random seeds for all runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete\n",
      "Iteration  0, inertia 116403.036\n",
      "Iteration  1, inertia 58351.852\n",
      "Iteration  2, inertia 58297.635\n",
      "Iteration  3, inertia 58261.706\n",
      "Iteration  4, inertia 58229.069\n",
      "Iteration  5, inertia 58220.610\n",
      "Iteration  6, inertia 58219.679\n",
      "Iteration  7, inertia 58219.221\n",
      "Iteration  8, inertia 58218.996\n",
      "Iteration  9, inertia 58218.868\n",
      "Iteration 10, inertia 58218.790\n",
      "Iteration 11, inertia 58218.744\n",
      "Iteration 12, inertia 58218.713\n",
      "Iteration 13, inertia 58218.688\n",
      "Iteration 14, inertia 58218.672\n",
      "Iteration 15, inertia 58218.659\n",
      "Iteration 16, inertia 58218.653\n",
      "Iteration 17, inertia 58218.649\n",
      "Iteration 18, inertia 58218.647\n",
      "Iteration 19, inertia 58218.645\n",
      "Iteration 20, inertia 58218.644\n",
      "Iteration 21, inertia 58218.643\n",
      "Iteration 22, inertia 58218.643\n",
      "Iteration 23, inertia 58218.642\n",
      "Iteration 24, inertia 58218.642\n",
      "Converged at iteration 24: center shift 0.000000e+00 within tolerance 1.803739e-10\n",
      "Initialization complete\n",
      "Iteration  0, inertia 116703.253\n",
      "Iteration  1, inertia 58287.513\n",
      "Iteration  2, inertia 58254.956\n",
      "Iteration  3, inertia 58242.587\n",
      "Iteration  4, inertia 58229.950\n",
      "Iteration  5, inertia 58228.858\n",
      "Iteration  6, inertia 58228.566\n",
      "Iteration  7, inertia 58228.425\n",
      "Iteration  8, inertia 58228.339\n",
      "Iteration  9, inertia 58228.279\n",
      "Iteration 10, inertia 58228.245\n",
      "Iteration 11, inertia 58228.224\n",
      "Iteration 12, inertia 58228.209\n",
      "Iteration 13, inertia 58228.199\n",
      "Iteration 14, inertia 58228.193\n",
      "Iteration 15, inertia 58228.187\n",
      "Iteration 16, inertia 58228.181\n",
      "Iteration 17, inertia 58228.175\n",
      "Iteration 18, inertia 58228.170\n",
      "Iteration 19, inertia 58228.165\n",
      "Iteration 20, inertia 58228.161\n",
      "Iteration 21, inertia 58228.153\n",
      "Iteration 22, inertia 58228.148\n",
      "Iteration 23, inertia 58228.143\n",
      "Iteration 24, inertia 58228.139\n",
      "Iteration 25, inertia 58228.134\n",
      "Iteration 26, inertia 58228.127\n",
      "Iteration 27, inertia 58228.121\n",
      "Iteration 28, inertia 58228.116\n",
      "Iteration 29, inertia 58228.112\n",
      "Iteration 30, inertia 58228.107\n",
      "Iteration 31, inertia 58228.103\n",
      "Iteration 32, inertia 58228.099\n",
      "Iteration 33, inertia 58228.094\n",
      "Iteration 34, inertia 58228.089\n",
      "Iteration 35, inertia 58228.084\n",
      "Iteration 36, inertia 58228.080\n",
      "Iteration 37, inertia 58228.077\n",
      "Iteration 38, inertia 58228.073\n",
      "Iteration 39, inertia 58228.069\n",
      "Iteration 40, inertia 58228.067\n",
      "Iteration 41, inertia 58228.064\n",
      "Iteration 42, inertia 58228.061\n",
      "Iteration 43, inertia 58228.059\n",
      "Iteration 44, inertia 58228.055\n",
      "Iteration 45, inertia 58228.052\n",
      "Iteration 46, inertia 58228.049\n",
      "Iteration 47, inertia 58228.046\n",
      "Iteration 48, inertia 58228.041\n",
      "Iteration 49, inertia 58228.037\n",
      "Iteration 50, inertia 58228.031\n",
      "Iteration 51, inertia 58228.026\n",
      "Iteration 52, inertia 58228.020\n",
      "Iteration 53, inertia 58228.014\n",
      "Iteration 54, inertia 58228.007\n",
      "Iteration 55, inertia 58227.999\n",
      "Iteration 56, inertia 58227.990\n",
      "Iteration 57, inertia 58227.980\n",
      "Iteration 58, inertia 58227.967\n",
      "Iteration 59, inertia 58227.953\n",
      "Iteration 60, inertia 58227.939\n",
      "Iteration 61, inertia 58227.919\n",
      "Iteration 62, inertia 58227.898\n",
      "Iteration 63, inertia 58227.869\n",
      "Iteration 64, inertia 58227.824\n",
      "Iteration 65, inertia 58227.757\n",
      "Iteration 66, inertia 58227.594\n",
      "Iteration 67, inertia 58227.249\n",
      "Iteration 68, inertia 58226.789\n",
      "Iteration 69, inertia 58226.341\n",
      "Iteration 70, inertia 58225.927\n",
      "Iteration 71, inertia 58225.488\n",
      "Iteration 72, inertia 58225.146\n",
      "Iteration 73, inertia 58224.914\n",
      "Iteration 74, inertia 58224.774\n",
      "Iteration 75, inertia 58224.698\n",
      "Iteration 76, inertia 58224.654\n",
      "Iteration 77, inertia 58224.632\n",
      "Iteration 78, inertia 58224.621\n",
      "Iteration 79, inertia 58224.615\n",
      "Iteration 80, inertia 58224.610\n",
      "Iteration 81, inertia 58224.606\n",
      "Iteration 82, inertia 58224.604\n",
      "Iteration 83, inertia 58224.602\n",
      "Iteration 84, inertia 58224.602\n",
      "Iteration 85, inertia 58224.601\n",
      "Iteration 86, inertia 58224.601\n",
      "Iteration 87, inertia 58224.600\n",
      "Iteration 88, inertia 58224.600\n",
      "Iteration 89, inertia 58224.600\n",
      "Iteration 90, inertia 58224.600\n",
      "Iteration 91, inertia 58224.600\n",
      "Iteration 92, inertia 58224.600\n",
      "Converged at iteration 92: center shift 0.000000e+00 within tolerance 1.803739e-10\n",
      "Initialization complete\n",
      "Iteration  0, inertia 115852.884\n",
      "Iteration  1, inertia 58340.045\n",
      "Iteration  2, inertia 58276.720\n",
      "Iteration  3, inertia 58248.266\n",
      "Iteration  4, inertia 58229.618\n",
      "Iteration  5, inertia 58225.825\n",
      "Iteration  6, inertia 58223.213\n",
      "Iteration  7, inertia 58220.837\n",
      "Iteration  8, inertia 58219.389\n",
      "Iteration  9, inertia 58218.996\n",
      "Iteration 10, inertia 58218.908\n",
      "Iteration 11, inertia 58218.880\n",
      "Iteration 12, inertia 58218.860\n",
      "Iteration 13, inertia 58218.845\n",
      "Iteration 14, inertia 58218.831\n",
      "Iteration 15, inertia 58218.819\n",
      "Iteration 16, inertia 58218.805\n",
      "Iteration 17, inertia 58218.789\n",
      "Iteration 18, inertia 58218.774\n",
      "Iteration 19, inertia 58218.760\n",
      "Iteration 20, inertia 58218.746\n",
      "Iteration 21, inertia 58218.733\n",
      "Iteration 22, inertia 58218.720\n",
      "Iteration 23, inertia 58218.708\n",
      "Iteration 24, inertia 58218.698\n",
      "Iteration 25, inertia 58218.690\n",
      "Iteration 26, inertia 58218.684\n",
      "Iteration 27, inertia 58218.680\n",
      "Iteration 28, inertia 58218.675\n",
      "Iteration 29, inertia 58218.672\n",
      "Iteration 30, inertia 58218.669\n",
      "Iteration 31, inertia 58218.667\n",
      "Iteration 32, inertia 58218.665\n",
      "Iteration 33, inertia 58218.664\n",
      "Iteration 34, inertia 58218.662\n",
      "Iteration 35, inertia 58218.661\n",
      "Iteration 36, inertia 58218.659\n",
      "Iteration 37, inertia 58218.658\n",
      "Iteration 38, inertia 58218.657\n",
      "Iteration 39, inertia 58218.656\n",
      "Iteration 40, inertia 58218.655\n",
      "Iteration 41, inertia 58218.654\n",
      "Iteration 42, inertia 58218.654\n",
      "Iteration 43, inertia 58218.654\n",
      "Iteration 44, inertia 58218.654\n",
      "Iteration 45, inertia 58218.653\n",
      "Iteration 46, inertia 58218.653\n",
      "Iteration 47, inertia 58218.653\n",
      "Iteration 48, inertia 58218.653\n",
      "Iteration 49, inertia 58218.653\n",
      "Iteration 50, inertia 58218.653\n",
      "Iteration 51, inertia 58218.652\n",
      "Iteration 52, inertia 58218.652\n",
      "Iteration 53, inertia 58218.652\n",
      "Iteration 54, inertia 58218.652\n",
      "Iteration 55, inertia 58218.652\n",
      "Iteration 56, inertia 58218.652\n",
      "Iteration 57, inertia 58218.652\n",
      "Iteration 58, inertia 58218.651\n",
      "Iteration 59, inertia 58218.651\n",
      "Converged at iteration 59: center shift 0.000000e+00 within tolerance 1.803739e-10\n",
      "Initialization complete\n",
      "Iteration  0, inertia 116271.595\n",
      "Iteration  1, inertia 58331.385\n",
      "Iteration  2, inertia 58293.865\n",
      "Iteration  3, inertia 58273.580\n",
      "Iteration  4, inertia 58258.662\n",
      "Iteration  5, inertia 58249.167\n",
      "Iteration  6, inertia 58239.122\n",
      "Iteration  7, inertia 58234.589\n",
      "Iteration  8, inertia 58230.918\n",
      "Iteration  9, inertia 58227.055\n",
      "Iteration 10, inertia 58223.500\n",
      "Iteration 11, inertia 58220.799\n",
      "Iteration 12, inertia 58219.430\n",
      "Iteration 13, inertia 58218.934\n",
      "Iteration 14, inertia 58218.773\n",
      "Iteration 15, inertia 58218.718\n",
      "Iteration 16, inertia 58218.695\n",
      "Iteration 17, inertia 58218.685\n",
      "Iteration 18, inertia 58218.679\n",
      "Iteration 19, inertia 58218.674\n",
      "Iteration 20, inertia 58218.670\n",
      "Iteration 21, inertia 58218.667\n",
      "Iteration 22, inertia 58218.665\n",
      "Iteration 23, inertia 58218.664\n",
      "Iteration 24, inertia 58218.662\n",
      "Iteration 25, inertia 58218.660\n",
      "Iteration 26, inertia 58218.658\n",
      "Iteration 27, inertia 58218.656\n",
      "Iteration 28, inertia 58218.655\n",
      "Iteration 29, inertia 58218.654\n",
      "Iteration 30, inertia 58218.654\n",
      "Iteration 31, inertia 58218.654\n",
      "Iteration 32, inertia 58218.654\n",
      "Iteration 33, inertia 58218.653\n",
      "Iteration 34, inertia 58218.653\n",
      "Iteration 35, inertia 58218.652\n",
      "Iteration 36, inertia 58218.652\n",
      "Iteration 37, inertia 58218.652\n",
      "Iteration 38, inertia 58218.652\n",
      "Converged at iteration 38: center shift 0.000000e+00 within tolerance 1.803739e-10\n",
      "Initialization complete\n",
      "Iteration  0, inertia 115416.443\n",
      "Iteration  1, inertia 58236.393\n",
      "Iteration  2, inertia 58186.460\n",
      "Iteration  3, inertia 58180.442\n",
      "Iteration  4, inertia 58179.890\n",
      "Iteration  5, inertia 58179.704\n",
      "Iteration  6, inertia 58179.635\n",
      "Iteration  7, inertia 58179.607\n",
      "Iteration  8, inertia 58179.591\n",
      "Iteration  9, inertia 58179.584\n",
      "Iteration 10, inertia 58179.581\n",
      "Iteration 11, inertia 58179.579\n",
      "Iteration 12, inertia 58179.577\n",
      "Iteration 13, inertia 58179.576\n",
      "Iteration 14, inertia 58179.575\n",
      "Iteration 15, inertia 58179.575\n",
      "Iteration 16, inertia 58179.575\n",
      "Converged at iteration 16: center shift 0.000000e+00 within tolerance 1.803739e-10\n",
      "Initialization complete\n",
      "Iteration  0, inertia 115412.577\n",
      "Iteration  1, inertia 58251.021\n",
      "Iteration  2, inertia 58220.103\n",
      "Iteration  3, inertia 58212.599\n",
      "Iteration  4, inertia 58202.956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  5, inertia 58184.547\n",
      "Iteration  6, inertia 58179.865\n",
      "Iteration  7, inertia 58179.673\n",
      "Iteration  8, inertia 58179.617\n",
      "Iteration  9, inertia 58179.596\n",
      "Iteration 10, inertia 58179.586\n",
      "Iteration 11, inertia 58179.582\n",
      "Iteration 12, inertia 58179.580\n",
      "Iteration 13, inertia 58179.578\n",
      "Iteration 14, inertia 58179.577\n",
      "Iteration 15, inertia 58179.576\n",
      "Iteration 16, inertia 58179.575\n",
      "Iteration 17, inertia 58179.575\n",
      "Iteration 18, inertia 58179.575\n",
      "Converged at iteration 18: center shift 0.000000e+00 within tolerance 1.803739e-10\n"
     ]
    }
   ],
   "source": [
    "wiki_data = {'matrix': tf_idf, 'dataframe': wiki} # no 'centroid' for the root cluster\n",
    "left_child, right_child = bipartition(wiki_data, maxiter=100, num_runs=6, seed=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the contents of one of the two clusters, which we call the `left_child`, referring to the tree visualization above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_child"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is the content of the other cluster we named `right_child`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_child"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the bipartition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We provide you with a modified version of the visualization function from the k-means assignment. For each cluster, we print the top 5 words with highest TF-IDF weights in the centroid and display excerpts for the 8 nearest neighbors of the centroid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def display_single_tf_idf_cluster(cluster, map_index_to_word):\n",
    "    '''map_index_to_word: SFrame specifying the mapping betweeen words and column indices'''\n",
    "    \n",
    "    wiki_subset   = cluster['dataframe']\n",
    "    tf_idf_subset = cluster['matrix']\n",
    "    centroid      = cluster['centroid']\n",
    "    \n",
    "    # Print top 5 words with largest TF-IDF weights in the cluster\n",
    "    idx = centroid.argsort()[::-1]\n",
    "    for i in xrange(5):\n",
    "        print('{0:s}:{1:.3f}'.format(map_index_to_word['category'][idx[i]], centroid[idx[i]])),\n",
    "    print('')\n",
    "    \n",
    "    # Compute distances from the centroid to all data points in the cluster.\n",
    "    distances = pairwise_distances(tf_idf_subset, [centroid], metric='euclidean').flatten()\n",
    "    # compute nearest neighbors of the centroid within the cluster.\n",
    "    nearest_neighbors = distances.argsort()\n",
    "    # For 8 nearest neighbors, print the title as well as first 180 characters of text.\n",
    "    # Wrap the text at 80-character mark.\n",
    "    for i in xrange(8):\n",
    "        text = ' '.join(wiki_subset[nearest_neighbors[i]]['text'].split(None, 25)[0:25])\n",
    "        print('* {0:50s} {1:.5f}\\n  {2:s}\\n  {3:s}'.format(wiki_subset[nearest_neighbors[i]]['name'],\n",
    "              distances[nearest_neighbors[i]], text[:90], text[90:180] if len(text) > 90 else ''))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the two child clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_single_tf_idf_cluster(left_child, map_index_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_single_tf_idf_cluster(right_child, map_index_to_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The left cluster consists of athletes, whereas the right cluster consists of non-athletes. So far, we have a single-level hierarchy consisting of two clusters, as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "                                           Wikipedia\n",
    "                                               +\n",
    "                                               |\n",
    "                    +--------------------------+--------------------+\n",
    "                    |                                               |\n",
    "                    +                                               +\n",
    "                 Athletes                                      Non-athletes\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this hierarchy good enough? **When building a hierarchy of clusters, we must keep our particular application in mind.** For instance, we might want to build a **directory** for Wikipedia articles. A good directory would let you quickly narrow down your search to a small set of related articles. The categories of athletes and non-athletes are too general to facilitate efficient search. For this reason, we decide to build another level into our hierarchy of clusters with the goal of getting more specific cluster structure at the lower level. To that end, we subdivide both the `athletes` and `non-athletes` clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform recursive bipartitioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster of athletes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To help identify the clusters we've built so far, let's give them easy-to-read aliases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "athletes = left_child\n",
    "non_athletes = right_child"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the bipartition function, we produce two child clusters of the athlete cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bipartition the cluster of athletes\n",
    "left_child_athletes, right_child_athletes = bipartition(athletes, maxiter=100, num_runs=6, seed=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The left child cluster mainly consists of baseball players:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_single_tf_idf_cluster(left_child_athletes, map_index_to_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, the right child cluster is a mix of players in association football, Austrailian rules football and ice hockey:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_single_tf_idf_cluster(right_child_athletes, map_index_to_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our hierarchy of clusters now looks like this:\n",
    "```\n",
    "                                           Wikipedia\n",
    "                                               +\n",
    "                                               |\n",
    "                    +--------------------------+--------------------+\n",
    "                    |                                               |\n",
    "                    +                                               +\n",
    "                 Athletes                                      Non-athletes\n",
    "                    +\n",
    "                    |\n",
    "        +-----------+--------+\n",
    "        |                    |\n",
    "        |            association football/\n",
    "        +          Austrailian rules football/\n",
    "     baseball             ice hockey\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should we keep subdividing the clusters? If so, which cluster should we subdivide? To answer this question, we again think about our application. Since we organize our directory by topics, it would be nice to have topics that are about as coarse as each other. For instance, if one cluster is about baseball, we expect some other clusters about football, basketball, volleyball, and so forth. That is, **we would like to achieve similar level of granularity for all clusters.**\n",
    "\n",
    "Notice that the right child cluster is more coarse than the left child cluster. The right cluster posseses a greater variety of topics than the left (ice hockey/association football/Austrialian football vs. baseball). So the right child cluster should be subdivided further to produce finer child clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's give the clusters aliases as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseball            = left_child_athletes\n",
    "ice_hockey_football = right_child_athletes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster of ice hockey players and football players"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In answering the following quiz question, take a look at the topics represented in the top documents (those closest to the centroid), as well as the list of words with highest TF-IDF weights.\n",
    "\n",
    "Let us bipartition the cluster of ice hockey and football players."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_child_ihs, right_child_ihs = bipartition(ice_hockey_football, maxiter=100, num_runs=6, seed=1)\n",
    "display_single_tf_idf_cluster(left_child_ihs, map_index_to_word)\n",
    "display_single_tf_idf_cluster(right_child_ihs, map_index_to_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**. Which diagram best describes the hierarchy right after splitting the `ice_hockey_football` cluster? Refer to the quiz form for the diagrams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Caution**. The granularity criteria is an imperfect heuristic and must be taken with a grain of salt. It takes a lot of manual intervention to obtain a good hierarchy of clusters.\n",
    "\n",
    "* **If a cluster is highly mixed, the top articles and words may not convey the full picture of the cluster.** Thus, we may be misled if we judge the purity of clusters solely by their top documents and words. \n",
    "* **Many interesting topics are hidden somewhere inside the clusters but do not appear in the visualization.** We may need to subdivide further to discover new topics. For instance, subdividing the `ice_hockey_football` cluster led to the appearance of runners and golfers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster of non-athletes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us subdivide the cluster of non-athletes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bipartition the cluster of non-athletes\n",
    "left_child_non_athletes, right_child_non_athletes = bipartition(non_athletes, maxiter=100, num_runs=6, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_single_tf_idf_cluster(left_child_non_athletes, map_index_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_single_tf_idf_cluster(right_child_non_athletes, map_index_to_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neither of the clusters show clear topics, apart from the genders. Let us divide them further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_non_athletes = left_child_non_athletes\n",
    "female_non_athletes = right_child_non_athletes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**. Let us bipartition the clusters `male_non_athletes` and `female_non_athletes`. Which diagram best describes the resulting hierarchy of clusters for the non-athletes? Refer to the quiz for the diagrams.\n",
    "\n",
    "**Note**. Use `maxiter=100, num_runs=6, seed=1` for consistency of output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exp-python3",
   "language": "python",
   "name": "exp-python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
